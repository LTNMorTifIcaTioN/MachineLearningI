<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="AutoImportSettings">
    <option name="autoReloadType" value="SELECTIVE" />
  </component>
  <component name="ChangeListManager">
    <list default="true" id="2782bf78-f43b-45e5-91d6-2e8dc079138c" name="Changes" comment="Unidade_III_3">
      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
    </list>
    <option name="SHOW_DIALOG" value="false" />
    <option name="HIGHLIGHT_CONFLICTS" value="true" />
    <option name="HIGHLIGHT_NON_ACTIVE_CHANGELIST" value="false" />
    <option name="LAST_RESOLUTION" value="IGNORE" />
  </component>
  <component name="FileTemplateManagerImpl">
    <option name="RECENT_TEMPLATES">
      <list>
        <option value="Python Script" />
      </list>
    </option>
  </component>
  <component name="Git.Settings">
    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
  </component>
  <component name="MarkdownSettingsMigration">
    <option name="stateVersion" value="1" />
  </component>
  <component name="ProblemsViewState">
    <option name="selectedTabId" value="CurrentFile" />
  </component>
  <component name="ProjectColorInfo">{
  &quot;associatedIndex&quot;: 8
}</component>
  <component name="ProjectId" id="2bxyHe2boBwQOc00X2xYjysiNb6" />
  <component name="ProjectLevelVcsManager" settingsEditedManually="true" />
  <component name="ProjectViewState">
    <option name="hideEmptyMiddlePackages" value="true" />
    <option name="showLibraryContents" value="true" />
  </component>
  <component name="PropertiesComponent">{
  &quot;keyToString&quot;: {
    &quot;Python.Aula_1_Introducao_ao_aprendizado_de_maquina.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_1_Teoria_da_probabilidade.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_2_Modelos_de_aprendizagem_de_maquina.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_2_Probabilidade_Bayesiana.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_2_Transformacoes_lineares.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_3_Clusterizacao.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_3_Decisao_em_ML.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_3_Densidades_probabilisticas.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_3_Distribuicoes_Probabilisticas.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_4_Algoritmos_de_Classificacao.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_4_Modelos_de_selecao.executor&quot;: &quot;Run&quot;,
    &quot;Python.Aula_4_Redes_neurais.executor&quot;: &quot;Run&quot;,
    &quot;RunOnceActivity.OpenProjectViewOnStart&quot;: &quot;true&quot;,
    &quot;RunOnceActivity.ShowReadmeOnStart&quot;: &quot;true&quot;,
    &quot;git-widget-placeholder&quot;: &quot;main&quot;,
    &quot;last_opened_file_path&quot;: &quot;G:/.shortcut-targets-by-id/1-0eJugp2mhHVgylXYxSrV79OPbp72CNB/Cloud Drive/Documentos/Arquivos PDF, PPT, DOC/Ciências de Dados - Anhanguera Ampli/Inteligência Artificial/Machine Learning I/MachineLearningI&quot;,
    &quot;node.js.detected.package.eslint&quot;: &quot;true&quot;,
    &quot;node.js.detected.package.tslint&quot;: &quot;true&quot;,
    &quot;node.js.selected.package.eslint&quot;: &quot;(autodetect)&quot;,
    &quot;node.js.selected.package.tslint&quot;: &quot;(autodetect)&quot;,
    &quot;nodejs_package_manager_path&quot;: &quot;npm&quot;,
    &quot;settings.editor.selected.configurable&quot;: &quot;project.propVCSSupport.Mappings&quot;,
    &quot;vue.rearranger.settings.migration&quot;: &quot;true&quot;
  }
}</component>
  <component name="RecentsManager">
    <key name="MoveFile.RECENT_KEYS">
      <recent name="G:\.shortcut-targets-by-id\1-0eJugp2mhHVgylXYxSrV79OPbp72CNB\Cloud Drive\Documentos\Arquivos PDF, PPT, DOC\Ciências de Dados - Anhanguera Ampli\Inteligência Artificial\Machine Learning I\MachineLearningI\Unidade_II" />
    </key>
  </component>
  <component name="RunManager" selected="Python.Aula_4_Algoritmos_de_Classificacao">
    <configuration name="Aula_1_Distribuicoes_Probabilisticas" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="MachineLearningI" />
      <option name="ENV_FILES" value="" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Unidade_III" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="G:\.shortcut-targets-by-id\1-0eJugp2mhHVgylXYxSrV79OPbp72CNB\Cloud Drive\Documentos\Arquivos PDF, PPT, DOC\Ciências de Dados - Anhanguera Ampli\Inteligência Artificial\Machine Learning I\MachineLearningI\Unidade_III\Aula_1_Distribuicoes_Probabilisticas.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="Aula_2_Transformacoes_lineares" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="MachineLearningI" />
      <option name="ENV_FILES" value="" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Unidade_III" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Unidade_III/Aula_2_Transformacoes_lineares.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="Aula_3_Clusterizacao" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="MachineLearningI" />
      <option name="ENV_FILES" value="" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Unidade_III" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="Aula_4_Algoritmos_de_Classificacao" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="MachineLearningI" />
      <option name="ENV_FILES" value="" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Unidade_III" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <configuration name="Aula_4_Modelos_de_selecao" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
      <module name="MachineLearningI" />
      <option name="ENV_FILES" value="" />
      <option name="INTERPRETER_OPTIONS" value="" />
      <option name="PARENT_ENVS" value="true" />
      <envs>
        <env name="PYTHONUNBUFFERED" value="1" />
      </envs>
      <option name="SDK_HOME" value="" />
      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/Unidade_II" />
      <option name="IS_MODULE_SDK" value="true" />
      <option name="ADD_CONTENT_ROOTS" value="true" />
      <option name="ADD_SOURCE_ROOTS" value="true" />
      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/Unidade_II/Aula_4_Modelos_de_selecao.py" />
      <option name="PARAMETERS" value="" />
      <option name="SHOW_COMMAND_LINE" value="false" />
      <option name="EMULATE_TERMINAL" value="false" />
      <option name="MODULE_MODE" value="false" />
      <option name="REDIRECT_INPUT" value="false" />
      <option name="INPUT_FILE" value="" />
      <method v="2" />
    </configuration>
    <recent_temporary>
      <list>
        <item itemvalue="Python.Aula_4_Algoritmos_de_Classificacao" />
        <item itemvalue="Python.Aula_2_Transformacoes_lineares" />
        <item itemvalue="Python.Aula_3_Clusterizacao" />
        <item itemvalue="Python.Aula_1_Distribuicoes_Probabilisticas" />
        <item itemvalue="Python.Aula_4_Modelos_de_selecao" />
      </list>
    </recent_temporary>
  </component>
  <component name="SharedIndexes">
    <attachedChunks>
      <set>
        <option value="bundled-python-sdk-5a2391486177-2887949eec09-com.jetbrains.pycharm.pro.sharedIndexes.bundled-PY-233.13763.11" />
      </set>
    </attachedChunks>
  </component>
  <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
  <component name="TaskManager">
    <task active="true" id="Default" summary="Default task">
      <changelist id="2782bf78-f43b-45e5-91d6-2e8dc079138c" name="Changes" comment="" />
      <created>1707170938087</created>
      <option name="number" value="Default" />
      <option name="presentableId" value="Default" />
      <updated>1707170938087</updated>
      <workItem from="1707170982870" duration="5852000" />
      <workItem from="1707184721850" duration="770000" />
      <workItem from="1707270677292" duration="9143000" />
      <workItem from="1707283058235" duration="558000" />
      <workItem from="1707283806111" duration="2170000" />
      <workItem from="1707421146508" duration="8362000" />
      <workItem from="1707521717769" duration="8005000" />
      <workItem from="1707683072034" duration="1247000" />
      <workItem from="1707738932559" duration="10582000" />
      <workItem from="1707787346126" duration="43000" />
      <workItem from="1707853308116" duration="18408000" />
      <workItem from="1708029212942" duration="8357000" />
      <workItem from="1708047262160" duration="1024000" />
      <workItem from="1708048681406" duration="6642000" />
      <workItem from="1708127904559" duration="6938000" />
      <workItem from="1708384539415" duration="10154000" />
      <workItem from="1708468168118" duration="5789000" />
      <workItem from="1708547461150" duration="274000" />
      <workItem from="1708626183669" duration="145000" />
      <workItem from="1708634800230" duration="16000" />
      <workItem from="1708651158940" duration="7337000" />
      <workItem from="1708713297322" duration="3922000" />
      <workItem from="1708728797660" duration="8616000" />
    </task>
    <task id="LOCAL-00001" summary="Unidade_I">
      <option name="closed" value="true" />
      <created>1707537186229</created>
      <option name="number" value="00001" />
      <option name="presentableId" value="LOCAL-00001" />
      <option name="project" value="LOCAL" />
      <updated>1707537186229</updated>
    </task>
    <task id="LOCAL-00002" summary="Unidade_II_1">
      <option name="closed" value="true" />
      <created>1707756108936</created>
      <option name="number" value="00002" />
      <option name="presentableId" value="LOCAL-00002" />
      <option name="project" value="LOCAL" />
      <updated>1707756108936</updated>
    </task>
    <task id="LOCAL-00003" summary="Unidade_II_1">
      <option name="closed" value="true" />
      <created>1707756122277</created>
      <option name="number" value="00003" />
      <option name="presentableId" value="LOCAL-00003" />
      <option name="project" value="LOCAL" />
      <updated>1707756122277</updated>
    </task>
    <task id="LOCAL-00004" summary="Unidade_II_2">
      <option name="closed" value="true" />
      <created>1707885359119</created>
      <option name="number" value="00004" />
      <option name="presentableId" value="LOCAL-00004" />
      <option name="project" value="LOCAL" />
      <updated>1707885359119</updated>
    </task>
    <task id="LOCAL-00005" summary="Unidade_II_4">
      <option name="closed" value="true" />
      <created>1708143533419</created>
      <option name="number" value="00005" />
      <option name="presentableId" value="LOCAL-00005" />
      <option name="project" value="LOCAL" />
      <updated>1708143533419</updated>
    </task>
    <task id="LOCAL-00006" summary="Unidade_III_1">
      <option name="closed" value="true" />
      <created>1708405986135</created>
      <option name="number" value="00006" />
      <option name="presentableId" value="LOCAL-00006" />
      <option name="project" value="LOCAL" />
      <updated>1708405986135</updated>
    </task>
    <task id="LOCAL-00007" summary="Unidade_III_1">
      <option name="closed" value="true" />
      <created>1708406395993</created>
      <option name="number" value="00007" />
      <option name="presentableId" value="LOCAL-00007" />
      <option name="project" value="LOCAL" />
      <updated>1708406395993</updated>
    </task>
    <task id="LOCAL-00008" summary="Unidade_III_3">
      <option name="closed" value="true" />
      <created>1708665598551</created>
      <option name="number" value="00008" />
      <option name="presentableId" value="LOCAL-00008" />
      <option name="project" value="LOCAL" />
      <updated>1708665598551</updated>
    </task>
    <option name="localTasksCounter" value="9" />
    <servers />
  </component>
  <component name="TypeScriptGeneratedFilesManager">
    <option name="version" value="3" />
  </component>
  <component name="Vcs.Log.Tabs.Properties">
    <option name="TAB_STATES">
      <map>
        <entry key="MAIN">
          <value>
            <State />
          </value>
        </entry>
      </map>
    </option>
  </component>
  <component name="VcsManagerConfiguration">
    <MESSAGE value="Unidade_I" />
    <MESSAGE value="Unidade_II_1" />
    <MESSAGE value="Unidade_II_2" />
    <MESSAGE value="Unidade_II_4" />
    <MESSAGE value="Unidade_III_1" />
    <MESSAGE value="Unidade_III_3" />
    <option name="LAST_COMMIT_MESSAGE" value="Unidade_III_3" />
  </component>
  <component name="com.github.evgenys91.machinet.common.dslhistory.DslHistoryState">
    <option name="historyDtoById">
      <map>
        <entry key="0ef2f6">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
              <option name="id" value="0ef2f6" />
              <option name="initiateTms" value="1708738473173" />
              <option name="request" value="&quot;G:\.shortcut-targets-by-id\1-0eJugp2mhHVgylXYxSrV79OPbp72CNB\Cloud Drive\Documentos\Arquivos PDF, PPT, DOC\Ciências de Dados - Anhanguera Ampli\Inteligência Artificial\Machine Learning I\MachineLearningI\.venv\Scripts\python.exe&quot; &quot;G:\.shortcut-targets-by-id\1-0eJugp2mhHVgylXYxSrV79OPbp72CNB\Cloud Drive\Documentos\Arquivos PDF, PPT, DOC\Ciências de Dados - Anhanguera Ampli\Inteligência Artificial\Machine Learning I\MachineLearningI\Unidade_III\Aula_4_Algoritmos_de_Classificacao.py&quot; &#10;Traceback (most recent call last):&#10;  File &quot;G:\.shortcut-targets-by-id\1-0eJugp2mhHVgylXYxSrV79OPbp72CNB\Cloud Drive\Documentos\Arquivos PDF, PPT, DOC\Ciências de Dados - Anhanguera Ampli\Inteligência Artificial\Machine Learning I\MachineLearningI\Unidade_III\Aula_4_Algoritmos_de_Classificacao.py&quot;, line 108, in &lt;module&gt;&#10;    distances, indices = knn.kneighbors(new_data)&#10;                         ^^^^^^^^^^^^^^^^^^^^^^^^&#10;  File &quot;D:\Program Files\Python311\Lib\site-packages\sklearn\neighbors\_base.py&quot;, line 804, in kneighbors&#10;    X = self._validate_data(X, accept_sparse=&quot;csr&quot;, reset=False, order=&quot;C&quot;)&#10;        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&#10;  File &quot;D:\Program Files\Python311\Lib\site-packages\sklearn\base.py&quot;, line 604, in _validate_data&#10;O novo dado foi classificado como: 1&#10;    out = check_array(X, input_name=&quot;X&quot;, **check_params)&#10;          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&#10;  File &quot;D:\Program Files\Python311\Lib\site-packages\sklearn\utils\validation.py&quot;, line 940, in check_array&#10;    raise ValueError(&#10;ValueError: Expected 2D array, got 1D array instead:&#10;array=[0 0].&#10;Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.&#10;&#10;Process finished with exit code 1" />
              <option name="response" value="" />
              <option name="responseDescription" value="O erro que você está enfrentando ocorre porque o novo dado que você está tentando classificar possui uma dimensão incorreta. O classificador KNN espera que os dados de entrada tenham duas dimensões, mas o novo dado fornecido possui apenas uma dimensão.&#10;&#10;Para corrigir esse erro, você pode usar a função `reshape` do NumPy para alterar a forma do novo dado de `(1,)` para `(1, 2)`. Isso garantirá que ele tenha a forma correta esperada pelo classificador KNN.&#10;&#10;Aqui está o código corrigido:&#10;&#10;```python&#10;# Gerar um novo dado não classificado&#10;new_data = np.array([[0, 0]])&#10;&#10;# Medir a distância do novo dado para os dados existentes&#10;distances, indices = knn.kneighbors(new_data)&#10;&#10;# Obter as classes dos vizinhos mais próximos&#10;nearest_labels = y[indices]&#10;&#10;# Contar a ocorrência de cada classe&#10;unique_classes, class_counts = np.unique(nearest_labels, return_counts=True)&#10;&#10;# Encontrar a classe mais frequente&#10;most_frequent_class = unique_classes[np.argmax(class_counts)]&#10;&#10;# Classificar o novo dado com a classe mais frequente&#10;new_data_class = most_frequent_class&#10;&#10;# Plotar os dados existentes&#10;plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', label='Dados existentes')&#10;&#10;# Plotar o novo dado não classificado&#10;plt.scatter(new_data[:, 0], new_data[:, 1], c='red', marker='x', label='Novo dado')&#10;&#10;# Plotar os vizinhos mais próximos&#10;plt.scatter(X[indices, 0], X[indices, 1], c=nearest_labels.flatten(), cmap='viridis', marker='s', label='Vizinhos mais próximos')&#10;&#10;plt.xlabel('Característica 1')&#10;plt.ylabel('Característica 2')&#10;plt.title('Classificação com KNN')&#10;plt.legend()&#10;plt.show()&#10;&#10;print(f'O novo dado foi classificado como: {new_data_class}')&#10;```&#10;&#10;Agora, o novo dado será corretamente classificado pelo classificador KNN." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708738478546" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="1da1ae">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_2_Transformacoes_lineares.py" />
                </list>
              </option>
              <option name="id" value="1da1ae" />
              <option name="initiateTms" value="1708665491532" />
              <option name="request" value="crie um algoritmo com exemplos gráficos de transformações lineares" />
              <option name="response" value="" />
              <option name="responseDescription" value="Claro! Aqui está um exemplo de algoritmo que demonstra algumas transformações lineares com exemplos gráficos:&#10;&#10;```python&#10;import numpy as np&#10;import matplotlib.pyplot as plt&#10;&#10;# Função para plotar os vetores no gráfico&#10;def plot_vectors(vectors, colors):&#10;    for vector, color in zip(vectors, colors):&#10;        plt.quiver(0, 0, vector[0], vector[1], angles='xy', scale_units='xy', scale=1, color=color)&#10;        plt.xlim(-10, 10)&#10;        plt.ylim(-10, 10)&#10;&#10;# Vetores de exemplo&#10;vectors = np.array([[2, 2], [-3, 1], [1, -3]])&#10;colors = ['r', 'g', 'b']&#10;&#10;# Transformação: Rotação de 45 graus no sentido anti-horário&#10;rotation_matrix = np.array([[np.cos(np.pi/4), -np.sin(np.pi/4)], [np.sin(np.pi/4), np.cos(np.pi/4)]])&#10;rotated_vectors = np.dot(vectors, rotation_matrix)&#10;&#10;# Transformação: Escala por um fator de 2&#10;scale_factor = 2&#10;scaled_vectors = vectors * scale_factor&#10;&#10;# Transformação: Reflexão em relação ao eixo x&#10;reflection_matrix = np.array([[1, 0], [0, -1]])&#10;reflected_vectors = np.dot(vectors, reflection_matrix)&#10;&#10;# Plotar os vetores originais&#10;plt.subplot(2, 2, 1)&#10;plt.title('Vetores Originais')&#10;plot_vectors(vectors, colors)&#10;&#10;# Plotar os vetores rotacionados&#10;plt.subplot(2, 2, 2)&#10;plt.title('Vetores Rotacionados')&#10;plot_vectors(rotated_vectors, colors)&#10;&#10;# Plotar os vetores escalados&#10;plt.subplot(2, 2, 3)&#10;plt.title('Vetores Escalados')&#10;plot_vectors(scaled_vectors, colors)&#10;&#10;# Plotar os vetores refletidos&#10;plt.subplot(2, 2, 4)&#10;plt.title('Vetores Refletidos')&#10;plot_vectors(reflected_vectors, colors)&#10;&#10;plt.tight_layout()&#10;plt.show()&#10;```&#10;&#10;Neste exemplo, temos três vetores de exemplo representados pelos arrays `vectors`. Em seguida, aplicamos três transformações lineares diferentes:&#10;&#10;1. Rotação de 45 graus no sentido anti-horário usando uma matriz de rotação.&#10;2. Escala por um fator de 2 multiplicando os vetores pelo fator de escala.&#10;3. Reflexão em relação ao eixo x usando uma matriz de reflexão.&#10;&#10;Em cada transformação, calculamos os vetores resultantes e os plotamos em um gráfico de dispersão usando a função `plot_vectors`. Cada transformação é mostrada em um subplot separado.&#10;&#10;Certifique-se de ter a biblioteca matplotlib instalada em seu ambiente Python para executar o código acima.&#10;&#10;Se você tiver mais dúvidas ou precisar de mais ajuda, por favor, me avise." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708665502506" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_2_Transformacoes_lineares.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="34605f">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
              <option name="id" value="34605f" />
              <option name="initiateTms" value="1708738305760" />
              <option name="request" value="calcule e retorne a distância euclidiana neste algoritmo:" />
              <option name="response" value="" />
              <option name="responseDescription" value="Claro! Para calcular a distância euclidiana entre o novo dado e os dados existentes, você pode usar a função `euclidean` da biblioteca `scipy.spatial.distance`. Aqui está o código para calcular e retornar a distância euclidiana:&#10;&#10;```python&#10;from scipy.spatial.distance import euclidean&#10;&#10;# Gerar um novo dado não classificado&#10;new_data = np.array([0, 0])&#10;&#10;# Medir a distância do novo dado para os dados existentes&#10;distances, indices = knn.kneighbors(new_data)&#10;&#10;# Calcular a distância euclidiana&#10;euclidean_distance = euclidean(new_data, X[indices])&#10;&#10;# Retornar a distância euclidiana&#10;print(f&quot;A distância euclidiana entre o novo dado e os vizinhos mais próximos é: {euclidean_distance}&quot;)&#10;```&#10;&#10;Neste código, importamos a função `euclidean` da biblioteca `scipy.spatial.distance`. Em seguida, calculamos a distância euclidiana entre o novo dado (`new_data`) e os vizinhos mais próximos (`X[indices]`). Por fim, imprimimos a distância euclidiana.&#10;&#10;Execute esse código e você obterá a distância euclidiana entre o novo dado e os vizinhos mais próximos. Se você tiver mais dúvidas ou precisar de mais ajuda, por favor, me avise." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708738311513" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="472960">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
              <option name="id" value="472960" />
              <option name="initiateTms" value="1708662370716" />
              <option name="request" value="Traceback (most recent call last):&#10;  File &quot;G:\.shortcut-targets-by-id\1-0eJugp2mhHVgylXYxSrV79OPbp72CNB\Cloud Drive\Documentos\Arquivos PDF, PPT, DOC\Ciências de Dados - Anhanguera Ampli\Inteligência Artificial\Machine Learning I\MachineLearningI\Unidade_III\Aula_3_Clusterizacao.py&quot;, line 34, in &lt;module&gt;&#10;    kmeans = KMeans(n_clusters=3, random_state=0).fit(X) #aplicação do algortimo kmeans no conjunto de dados&#10;                                                      ^&#10;NameError: name 'X' is not defined" />
              <option name="response" value="" />
              <option name="responseDescription" value="Desculpe pelo erro novamente. Parece que a variável `X` não foi definida antes de ser usada na linha em que você está aplicando o algoritmo K-Means.&#10;&#10;Para corrigir o erro, você precisa fornecer os dados de entrada para o algoritmo K-Means e atribuí-los à variável `X`. Você pode fazer isso selecionando as colunas relevantes do seu conjunto de dados `dataset` e convertendo-as em uma matriz numpy. Aqui está um exemplo de como fazer isso:&#10;&#10;```python&#10;X = dataset[['coluna1', 'coluna2', 'coluna3']].values&#10;```&#10;&#10;Substitua `'coluna1', 'coluna2', 'coluna3'` pelos nomes das colunas relevantes do seu conjunto de dados que você deseja usar para a clusterização.&#10;&#10;Certifique-se de que as colunas selecionadas existam no seu conjunto de dados e que os nomes estejam corretos.&#10;&#10;Após definir a variável `X`, você pode aplicar o algoritmo K-Means da seguinte forma:&#10;&#10;```python&#10;kmeans = KMeans(n_clusters=3, random_state=0).fit(X)  # aplicação do algoritmo K-Means no conjunto de dados&#10;```&#10;&#10;Lembre-se de substituir `3` pelo número desejado de clusters.&#10;&#10;Se você tiver mais dúvidas ou precisar de mais ajuda, por favor, me avise." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708662375463" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="4e92d6">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
              <option name="id" value="4e92d6" />
              <option name="initiateTms" value="1708664231138" />
              <option name="request" value="corrija o algoritmo para se adequar: Vejamos as principais etapas envolvidas em um algoritmo K-means:&#10;&#10;&gt; Definição de um ‘K’, o número de clusters da sua base de dados.&#10;&gt; Definir o centroide para cada cluster para realizar o agrupamento.&#10;&gt; Calcular, para cada ponto, o centroide de menor distância.&#10;&gt; Reposicionar o centroide, devendo ser a média da posição de todos os pontos do cluster.&#10;&gt; Os dois últimos passos são repetidos até chegar no resultado final." />
              <option name="response" value="" />
              <option name="responseDescription" value="Desculpe pelo equívoco. Vou corrigir o algoritmo para se adequar às etapas corretas do algoritmo K-means. Aqui está o código atualizado:&#10;&#10;```python&#10;import numpy as np&#10;import pandas as pd&#10;import matplotlib.pyplot as plt&#10;from sklearn.cluster import KMeans&#10;&#10;exemplo = &quot;G:/.shortcut-targets-by-id/1-0eJugp2mhHVgylXYxSrV79OPbp72CNB/Cloud Drive/Documentos/Arquivos PDF, PPT, DOC/Ciências de Dados - Anhanguera Ampli/Inteligência Artificial/Machine Learning I/MachineLearningI/Datasets/Vendas-Arquivo2.csv&quot;&#10;&#10;dataset = pd.read_csv(exemplo, sep=&quot;;&quot;)  # nesse momento devemos fazer a leitura do nosso dataset&#10;&#10;X = dataset[['MESCOMPRA', 'PESOGRAMAS', 'VALOR']].values&#10;&#10;kmeans = KMeans(n_clusters=3, random_state=0, n_init=10).fit(X)  # aplicação do algoritmo K-Means no conjunto de dados&#10;&#10;# Exibir os clusters antes do K-Means&#10;plt.scatter(X[:, 0], X[:, 1], c='blue', label='Dados Originais')&#10;plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x', label='Centroides Iniciais')&#10;plt.xlabel('MESCOMPRA')&#10;plt.ylabel('PESOGRAMAS')&#10;plt.title('Clusters Antes do K-Means')&#10;plt.legend()&#10;plt.show()&#10;&#10;# Executar o algoritmo K-Means&#10;while True:&#10;    X_clustered = kmeans.predict(X)&#10;    old_centroids = kmeans.cluster_centers_.copy()&#10;    kmeans.cluster_centers_ = np.array([X[X_clustered == i].mean(axis=0) for i in range(kmeans.n_clusters)])&#10;    if np.all(old_centroids == kmeans.cluster_centers_):&#10;        break&#10;&#10;# Exibir os clusters após o K-Means&#10;plt.scatter(X[:, 0], X[:, 1], c=X_clustered, cmap='viridis', label='Clusters')&#10;plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x', label='Centroides Finais')&#10;plt.xlabel('MESCOMPRA')&#10;plt.ylabel('PESOGRAMAS')&#10;plt.title('Clusters Após o K-Means')&#10;plt.legend()&#10;plt.show()&#10;```&#10;&#10;Neste código, adicionamos um loop while para executar as etapas corretas do algoritmo K-means:&#10;&#10;1. Atribuição inicial dos pontos aos clusters com base nos centroides iniciais.&#10;2. Cálculo dos novos centroides como a média da posição de todos os pontos em cada cluster.&#10;3. Verificação se os centroides antigos são iguais aos novos centroides. Se forem iguais, o loop é interrompido e o algoritmo é considerado concluído.&#10;&#10;Após a execução do algoritmo K-means, exibimos os clusters resultantes e os centroides finais em um gráfico de dispersão.&#10;&#10;Certifique-se de ter a biblioteca matplotlib instalada em seu ambiente Python para executar o código acima.&#10;&#10;Se você tiver mais dúvidas ou precisar de mais ajuda, por favor, me avise." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708664241201" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="51b819">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
              <option name="id" value="51b819" />
              <option name="initiateTms" value="1708738329615" />
              <option name="request" value="calcule e retorne a distância euclidiana neste algoritmo: &#9;import numpy as np&#10;import matplotlib.pyplot as plt&#10;from sklearn.datasets import make_blobs&#10;from sklearn.neighbors import KNeighborsClassifier&#10;&#10;# Gerar dados de exemplo&#10;X, y = make_blobs(n_samples=100, centers=2, random_state=42)&#10;&#10;# Criar o classificador KNN&#10;k = 3  # número de vizinhos mais próximos a considerar&#10;knn = KNeighborsClassifier(n_neighbors=k)&#10;&#10;# Treinar o classificador com os dados existentes&#10;knn.fit(X, y)&#10;&#10;# Gerar um novo dado não classificado&#10;new_data = np.array([[0, 0]])&#10;&#10;# Medir a distância do novo dado para os dados existentes&#10;distances, indices = knn.kneighbors(new_data)&#10;&#10;# Obter as classes dos vizinhos mais próximos&#10;nearest_labels = y[indices]&#10;&#10;# Contar a ocorrência de cada classe&#10;unique_classes, class_counts = np.unique(nearest_labels, return_counts=True)&#10;&#10;# Encontrar a classe mais frequente&#10;most_frequent_class = unique_classes[np.argmax(class_counts)]&#10;&#10;# Classificar o novo dado com a classe mais frequente&#10;new_data_class = most_frequent_class&#10;&#10;# Plotar os dados existentes&#10;plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', label='Dados existentes')&#10;&#10;# Plotar o novo dado não classificado&#10;plt.scatter(new_data[:, 0], new_data[:, 1], c='red', marker='x', label='Novo dado')&#10;&#10;# Plotar os vizinhos mais próximos&#10;plt.scatter(X[indices, 0], X[indices, 1], c=nearest_labels.flatten(), cmap='viridis', marker='s', label='Vizinhos mais próximos')&#10;&#10;plt.xlabel('Característica 1')&#10;plt.ylabel('Característica 2')&#10;plt.title('Classificação com KNN')&#10;plt.legend()&#10;plt.show()&#10;&#10;print(f'O novo dado foi classificado como: {new_data_class}')" />
              <option name="response" value="" />
              <option name="responseDescription" value="Desculpe, mas para calcular a distância euclidiana, preciso ter acesso ao código completo do algoritmo KNN. No código fornecido, não há uma função específica para calcular a distância euclidiana. &#10;&#10;Se você puder fornecer o código completo do algoritmo KNN, incluindo a definição da função `euclidean_distance` ou qualquer outra função que calcule a distância euclidiana, ficarei feliz em ajudar a calcular e retornar a distância euclidiana." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708738335239" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="526e83">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
              <option name="id" value="526e83" />
              <option name="initiateTms" value="1708738176368" />
              <option name="request" value="retorne o valor da distância euclidiana" />
              <option name="response" value="" />
              <option name="responseDescription" value="Para calcular a distância euclidiana entre dois pontos em um espaço bidimensional, você pode usar a função `euclidean` da biblioteca `scipy.spatial.distance`. Aqui está um exemplo de como calcular a distância euclidiana entre o novo dado não classificado e os vizinhos mais próximos:&#10;&#10;```python&#10;from scipy.spatial.distance import euclidean&#10;&#10;# Calcular a distância euclidiana entre o novo dado e os vizinhos mais próximos&#10;distances = [euclidean(new_data.flatten(), X[index]) for index in indices]&#10;&#10;# Imprimir as distâncias euclidianas&#10;for i, distance in enumerate(distances):&#10;    print(f&quot;A distância euclidiana entre o novo dado e o vizinho {i+1} é: {distance}&quot;)&#10;```&#10;&#10;Neste exemplo, importamos a função `euclidean` da biblioteca `scipy.spatial.distance`. Em seguida, calculamos a distância euclidiana entre o novo dado (`new_data`) e cada vizinho mais próximo (`X[index]`) usando um loop.&#10;&#10;Por fim, imprimimos as distâncias euclidianas para cada vizinho mais próximo.&#10;&#10;Certifique-se de ter a biblioteca `scipy` instalada em seu ambiente Python para executar o código acima.&#10;&#10;Se você tiver mais dúvidas ou precisar de mais ajuda, por favor, me avise." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708738180549" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="5285a1">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
              <option name="id" value="5285a1" />
              <option name="initiateTms" value="1708740852423" />
              <option name="request" value="corrija este algoritmo: from sklearn.tree import DecisionTreeClassifier&#10;from sklearn.metrics import accuracy_score&#10;&#10;np.random.seed(SEED)&#10;&#10;model = DecisionTreeClassifier(max_depth=2)&#10;&#10;model.fit(X_train, y_train)&#10;&#10;predict = model.predict(X_test)&#10;&#10;accuracy = accuracy_score(y_test, predict) * 100&#10;&#10;print(&quot;A acuracia foi de {: .2f}%.&quot;.format(accuracy))" />
              <option name="response" value="" />
              <option name="responseDescription" value="O algoritmo parece estar correto, mas há uma variável `SEED` que não foi definida. Você precisa definir um valor para `SEED` antes de executar o código. Além disso, as variáveis `X_train`, `y_train`, `X_test` e `y_test` não estão definidas no código fornecido. Essas variáveis devem conter os dados de treinamento e teste para o modelo de árvore de decisão.&#10;&#10;Aqui está um exemplo de como você pode corrigir o código, definindo um valor para `SEED` e fornecendo os dados de treinamento e teste:&#10;&#10;```python&#10;from sklearn.tree import DecisionTreeClassifier&#10;from sklearn.metrics import accuracy_score&#10;import numpy as np&#10;&#10;SEED = 42&#10;&#10;# Definir os dados de treinamento e teste&#10;X_train = ...&#10;y_train = ...&#10;X_test = ...&#10;y_test = ...&#10;&#10;np.random.seed(SEED)&#10;&#10;model = DecisionTreeClassifier(max_depth=2)&#10;&#10;model.fit(X_train, y_train)&#10;&#10;predict = model.predict(X_test)&#10;&#10;accuracy = accuracy_score(y_test, predict) * 100&#10;&#10;print(&quot;A acuracia foi de {:.2f}%.&quot;.format(accuracy))&#10;```&#10;&#10;Certifique-se de substituir `...` pelos seus dados de treinamento e teste reais." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708740857481" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="73a290">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
              <option name="id" value="73a290" />
              <option name="initiateTms" value="1708740326347" />
              <option name="request" value="resuma a precisão e o recall" />
              <option name="response" value="" />
              <option name="responseDescription" value="A precisão e o recall são métricas comumente usadas para avaliar a qualidade de um modelo de classificação.&#10;&#10;A precisão é a proporção de exemplos positivos corretamente classificados em relação ao total de exemplos classificados como positivos. Em outras palavras, a precisão mede a capacidade do modelo de evitar classificar erroneamente exemplos negativos como positivos. A fórmula da precisão é:&#10;&#10;Precisão = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Positivos)&#10;&#10;Por outro lado, o recall é a proporção de exemplos positivos corretamente classificados em relação ao total de exemplos positivos reais. O recall mede a capacidade do modelo de identificar corretamente exemplos positivos. A fórmula do recall é:&#10;&#10;Recall = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos)&#10;&#10;Em resumo, a precisão mede a precisão das previsões positivas do modelo, enquanto o recall mede a capacidade do modelo de encontrar todos os exemplos positivos.&#10;&#10;É importante observar que a precisão e o recall são métricas complementares e podem ter um trade-off entre si. Aumentar a precisão geralmente leva a uma diminuição no recall e vice-versa. Portanto, é importante considerar o contexto do problema e escolher a métrica mais adequada com base nos requisitos específicos do projeto." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708740330583" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="755ee2">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
              <option name="id" value="755ee2" />
              <option name="initiateTms" value="1708662110861" />
              <option name="request" value="# Clusterização hierárquica e K-Means&#10;import numpy as np&#10;&#10;import pandas as pd &#10;&#10;from sklearn.cluster import KMeans&#10;&#10;exemplo = &quot;Datasets/Vendas-Arquivo2.csv&quot;&#10;&#10;dataset = exemplo.read_csv  #nesse momento devemos fazer a leitura do nosso dataset&#10;&#10;kmeans = KMeans(n_clusters=3, random_state=0).fit(X) #aplicação do algortimo kmeans no conjunto de dados&#10;&#10;X_clustered = kmeans.fit_predict(X)" />
              <option name="response" value="" />
              <option name="responseDescription" value="O código fornecido realiza a clusterização hierárquica e o algoritmo K-Means em um conjunto de dados. Vou explicar brevemente cada um desses métodos.&#10;&#10;A clusterização hierárquica é uma técnica de agrupamento que organiza os dados em uma estrutura hierárquica de clusters. Ela começa considerando cada ponto de dados como um cluster individual e, em seguida, combina gradualmente os clusters em grupos maiores, com base em sua similaridade. Existem dois tipos principais de clusterização hierárquica: aglomerativa e divisiva. A aglomerativa começa com clusters individuais e os mescla em clusters maiores, enquanto a divisiva começa com um único cluster contendo todos os pontos de dados e os divide em clusters menores.&#10;&#10;O algoritmo K-Means é um método de agrupamento que divide os dados em k clusters, onde k é um número pré-definido. Ele atribui cada ponto de dados ao cluster mais próximo, com base na distância euclidiana entre os pontos e os centróides dos clusters. O algoritmo itera até que a atribuição dos pontos aos clusters não mude significativamente.&#10;&#10;No código fornecido, é feita a leitura de um arquivo de exemplo &quot;Vendas-Arquivo2.csv&quot; e em seguida é aplicado o algoritmo K-Means com 3 clusters no conjunto de dados. A variável &quot;X&quot; representa os dados de entrada. O resultado da clusterização é armazenado na variável &quot;X_clustered&quot;, que contém as atribuições de cluster para cada ponto de dados.&#10;&#10;É importante ressaltar que o código fornecido está incompleto, pois a leitura do arquivo CSV não está sendo feita corretamente. É necessário corrigir a linha &quot;dataset = exemplo.read_csv&quot; para realizar a leitura correta do arquivo. Além disso, a variável &quot;X&quot; não está definida no código fornecido, portanto é necessário fornecer os dados de entrada para o algoritmo K-Means.&#10;&#10;Caso você precise de mais informações ou precise de ajuda com outras partes do código, por favor, me informe." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708662118269" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="905f0b">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
              <option name="id" value="905f0b" />
              <option name="initiateTms" value="1708738243872" />
              <option name="request" value="Traceback (most recent call last):&#10;  File &quot;G:\.shortcut-targets-by-id\1-0eJugp2mhHVgylXYxSrV79OPbp72CNB\Cloud Drive\Documentos\Arquivos PDF, PPT, DOC\Ciências de Dados - Anhanguera Ampli\Inteligência Artificial\Machine Learning I\MachineLearningI\Unidade_III\Aula_4_Algoritmos_de_Classificacao.py&quot;, line 104, in &lt;module&gt;&#10;O novo dado foi classificado como: 1&#10;    distances = [euclidean(new_data.flatten(), X[index]) for index in indices]&#10;                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&#10;  File &quot;G:\.shortcut-targets-by-id\1-0eJugp2mhHVgylXYxSrV79OPbp72CNB\Cloud Drive\Documentos\Arquivos PDF, PPT, DOC\Ciências de Dados - Anhanguera Ampli\Inteligência Artificial\Machine Learning I\MachineLearningI\Unidade_III\Aula_4_Algoritmos_de_Classificacao.py&quot;, line 104, in &lt;listcomp&gt;&#10;    distances = [euclidean(new_data.flatten(), X[index]) for index in indices]&#10;                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^&#10;  File &quot;D:\Program Files\Python311\Lib\site-packages\scipy\spatial\distance.py&quot;, line 536, in euclidean&#10;    return minkowski(u, v, p=2, w=w)&#10;           ^^^^^^^^^^^^^^^^^^^^^^^^^&#10;  File &quot;D:\Program Files\Python311\Lib\site-packages\scipy\spatial\distance.py&quot;, line 480, in minkowski&#10;    v = _validate_vector(v)&#10;        ^^^^^^^^^^^^^^^^^^^&#10;  File &quot;D:\Program Files\Python311\Lib\site-packages\scipy\spatial\distance.py&quot;, line 318, in _validate_vector&#10;    raise ValueError(&quot;Input vector should be 1-D.&quot;)&#10;ValueError: Input vector should be 1-D." />
              <option name="response" value="" />
              <option name="responseDescription" value="Desculpe pelo erro. Parece que o novo dado (`new_data`) não está sendo fornecido como um vetor unidimensional. A função `euclidean` espera que os vetores de entrada sejam unidimensionais.&#10;&#10;Para corrigir o erro, você pode modificar a linha onde o novo dado é definido para garantir que ele seja um vetor unidimensional. Aqui está o código corrigido:&#10;&#10;```python&#10;# Gerar um novo dado não classificado&#10;new_data = np.array([0, 0])  # Modifique esta linha&#10;&#10;# Medir a distância do novo dado para os dados existentes&#10;distances, indices = knn.kneighbors(new_data)&#10;&#10;# Resto do código...&#10;```&#10;&#10;Neste exemplo, modificamos a linha onde o novo dado é definido para `new_data = np.array([0, 0])`. Isso garante que o novo dado seja um vetor unidimensional.&#10;&#10;Tente executar o código novamente após fazer essa modificação. Se você tiver mais dúvidas ou precisar de mais ajuda, por favor, me avise." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708738247905" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="9f2121">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
              <option name="id" value="9f2121" />
              <option name="initiateTms" value="1708662604634" />
              <option name="request" value="D:\Program Files\Python311\Lib\site-packages\sklearn\cluster\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning&#10;  super()._check_params_vs_input(X, default_n_init=10)&#10;D:\Program Files\Python311\Lib\site-packages\sklearn\cluster\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning&#10;  super()._check_params_vs_input(X, default_n_init=10)" />
              <option name="response" value="" />
              <option name="responseDescription" value="Essa mensagem de aviso é um aviso futuro do scikit-learn (sklearn) que informa que o valor padrão do parâmetro `n_init` será alterado de 10 para 'auto' na versão 1.4. O aviso sugere que você defina explicitamente o valor de `n_init` para suprimir o aviso.&#10;&#10;O parâmetro `n_init` é o número de vezes que o algoritmo K-Means será executado com diferentes centroides iniciais. O resultado final será o melhor resultado obtido entre as várias execuções.&#10;&#10;Para suprimir o aviso, você pode definir explicitamente o valor de `n_init` ao criar a instância do objeto KMeans. Por exemplo:&#10;&#10;```python&#10;kmeans = KMeans(n_clusters=3, random_state=0, n_init=10).fit(X)&#10;```&#10;&#10;Nesse exemplo, `n_init` é definido como 10 para corresponder ao valor padrão atual. Você pode ajustar esse valor de acordo com suas necessidades.&#10;&#10;Lembre-se de que esse aviso é apenas um aviso futuro e não afetará o funcionamento atual do seu código. No entanto, é uma boa prática atualizar seu código para evitar problemas futuros.&#10;&#10;Se você tiver mais dúvidas ou precisar de mais ajuda, por favor, me avise." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708662609990" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="a76784">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
              <option name="id" value="a76784" />
              <option name="initiateTms" value="1708662681778" />
              <option name="request" value="melhore este código e faça ele exibir os clusters  graficamente antes e após o k-means # Clusterização hierárquica e K-Means&#10;import numpy as np&#10;&#10;import pandas as pd&#10;&#10;from sklearn.cluster import KMeans&#10;&#10;exemplo = &quot;G:/.shortcut-targets-by-id/1-0eJugp2mhHVgylXYxSrV79OPbp72CNB/Cloud Drive/Documentos/Arquivos PDF, PPT, DOC/Ciências de Dados - Anhanguera Ampli/Inteligência Artificial/Machine Learning I/MachineLearningI/Datasets/Vendas-Arquivo2.csv&quot;&#10;&#10;dataset = pd.read_csv(exemplo, sep=&quot;;&quot;)  #nesse momento devemos fazer a leitura do nosso dataset&#10;&#10;X = dataset[['MESCOMPRA', 'PESOGRAMAS', 'VALOR']].values&#10;&#10;kmeans = KMeans(n_clusters=3, random_state=0, n_init=10).fit(X) #aplicação do algortimo kmeans no conjunto de dados&#10;&#10;X_clustered = kmeans.fit_predict(X)&#10;&#10;print(X_clustered)" />
              <option name="response" value="" />
              <option name="responseDescription" value="Para melhorar o código e exibir os clusters graficamente antes e após o K-Means, você pode usar a biblioteca matplotlib para criar visualizações. Aqui está o código atualizado:&#10;&#10;```python&#10;import numpy as np&#10;import pandas as pd&#10;import matplotlib.pyplot as plt&#10;from sklearn.cluster import KMeans&#10;&#10;exemplo = &quot;G:/.shortcut-targets-by-id/1-0eJugp2mhHVgylXYxSrV79OPbp72CNB/Cloud Drive/Documentos/Arquivos PDF, PPT, DOC/Ciências de Dados - Anhanguera Ampli/Inteligência Artificial/Machine Learning I/MachineLearningI/Datasets/Vendas-Arquivo2.csv&quot;&#10;&#10;dataset = pd.read_csv(exemplo, sep=&quot;;&quot;)  # nesse momento devemos fazer a leitura do nosso dataset&#10;&#10;X = dataset[['MESCOMPRA', 'PESOGRAMAS', 'VALOR']].values&#10;&#10;kmeans = KMeans(n_clusters=3, random_state=0, n_init=10).fit(X)  # aplicação do algoritmo K-Means no conjunto de dados&#10;&#10;X_clustered = kmeans.fit_predict(X)&#10;&#10;# Exibir os clusters antes do K-Means&#10;plt.scatter(X[:, 0], X[:, 1], c='blue', label='Dados Originais')&#10;plt.xlabel('MESCOMPRA')&#10;plt.ylabel('PESOGRAMAS')&#10;plt.title('Clusters Antes do K-Means')&#10;plt.legend()&#10;plt.show()&#10;&#10;# Exibir os clusters após o K-Means&#10;plt.scatter(X[:, 0], X[:, 1], c=X_clustered, cmap='viridis', label='Clusters')&#10;plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='x', label='Centroides')&#10;plt.xlabel('MESCOMPRA')&#10;plt.ylabel('PESOGRAMAS')&#10;plt.title('Clusters Após o K-Means')&#10;plt.legend()&#10;plt.show()&#10;```&#10;&#10;Neste código, adicionamos as importações necessárias para a biblioteca matplotlib e usamos a função `plt.scatter` para criar os gráficos de dispersão dos dados. No primeiro gráfico, exibimos os dados originais antes do K-Means, e no segundo gráfico, exibimos os clusters resultantes após a aplicação do K-Means. Também adicionamos rótulos aos eixos e títulos aos gráficos para melhorar a legibilidade.&#10;&#10;Certifique-se de ter a biblioteca matplotlib instalada em seu ambiente Python para executar o código acima.&#10;&#10;Se você tiver mais dúvidas ou precisar de mais ajuda, por favor, me avise." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708662689206" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="bcabdd">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
              <option name="id" value="bcabdd" />
              <option name="initiateTms" value="1708737943260" />
              <option name="request" value="crie um Algoritmo K-nearest neighbors - KNN com as seguintes etapas, e exiba graficamente o processo realizado e o resultado no final:&#9;As etapas do algoritmo são (ALPAYDIN, 2020):&#10;&#10;1 - Primeiro há o recebimento de um dado que não foi classificado previamente;&#10;2 - Há a medição da distância desse novo dado que não foi classificado anteriormente, levando em consideração os dados que já obtiveram sua classificação.&#10;3 - Obtém X menores distâncias.&#10;4 - Há uma verificação para identificar a classe de cada um dos dados que obtiverem a menor distância e realizar uma contagem de cada classe.&#10;5 - Verifica a classe que mais apareceu, considerando os dados que obtiverem as menores distâncias. Essa classe será seu resultado.&#10;6 - Realiza a classificação do dado com a classe que obtemos como resultado na fase 5. " />
              <option name="response" value="" />
              <option name="responseDescription" value="Aqui está um exemplo de implementação do algoritmo K-nearest neighbors (KNN) com as etapas descritas:&#10;&#10;```python&#10;import numpy as np&#10;import matplotlib.pyplot as plt&#10;from sklearn.datasets import make_blobs&#10;from sklearn.neighbors import KNeighborsClassifier&#10;&#10;# Gerar dados de exemplo&#10;X, y = make_blobs(n_samples=100, centers=2, random_state=42)&#10;&#10;# Criar o classificador KNN&#10;k = 3  # número de vizinhos mais próximos a considerar&#10;knn = KNeighborsClassifier(n_neighbors=k)&#10;&#10;# Treinar o classificador com os dados existentes&#10;knn.fit(X, y)&#10;&#10;# Gerar um novo dado não classificado&#10;new_data = np.array([[0, 0]])&#10;&#10;# Medir a distância do novo dado para os dados existentes&#10;distances, indices = knn.kneighbors(new_data)&#10;&#10;# Obter as classes dos vizinhos mais próximos&#10;nearest_labels = y[indices]&#10;&#10;# Contar a ocorrência de cada classe&#10;unique_classes, class_counts = np.unique(nearest_labels, return_counts=True)&#10;&#10;# Encontrar a classe mais frequente&#10;most_frequent_class = unique_classes[np.argmax(class_counts)]&#10;&#10;# Classificar o novo dado com a classe mais frequente&#10;new_data_class = most_frequent_class&#10;&#10;# Plotar os dados existentes&#10;plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', label='Dados existentes')&#10;&#10;# Plotar o novo dado não classificado&#10;plt.scatter(new_data[:, 0], new_data[:, 1], c='red', marker='x', label='Novo dado')&#10;&#10;# Plotar os vizinhos mais próximos&#10;plt.scatter(X[indices, 0], X[indices, 1], c=nearest_labels.flatten(), cmap='viridis', marker='s', label='Vizinhos mais próximos')&#10;&#10;plt.xlabel('Característica 1')&#10;plt.ylabel('Característica 2')&#10;plt.title('Classificação com KNN')&#10;plt.legend()&#10;plt.show()&#10;&#10;print(f'O novo dado foi classificado como: {new_data_class}')&#10;```&#10;&#10;Neste exemplo, utilizamos a biblioteca scikit-learn para gerar dados de exemplo com a função `make_blobs`. Em seguida, criamos um classificador KNN com `k = 3` vizinhos mais próximos.&#10;&#10;Após treinar o classificador com os dados existentes, geramos um novo dado não classificado (`new_data`) e medimos a distância desse dado para os dados existentes usando o método `kneighbors` do classificador KNN.&#10;&#10;Em seguida, obtemos as classes dos vizinhos mais próximos, contamos a ocorrência de cada classe e encontramos a classe mais frequente. Essa classe é considerada como a classificação do novo dado.&#10;&#10;Por fim, plotamos os dados existentes, o novo dado não classificado e os vizinhos mais próximos em um gráfico de dispersão. Também exibimos a classe atribuída ao novo dado.&#10;&#10;Certifique-se de ter as bibliotecas numpy, matplotlib e scikit-learn instaladas em seu ambiente Python para executar o código acima.&#10;&#10;Se você tiver mais dúvidas ou precisar de mais ajuda, por favor, me avise." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708737952496" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="f29c57">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
              <option name="id" value="f29c57" />
              <option name="initiateTms" value="1708662128400" />
              <option name="request" value="Traceback (most recent call last):&#10;  File &quot;G:\.shortcut-targets-by-id\1-0eJugp2mhHVgylXYxSrV79OPbp72CNB\Cloud Drive\Documentos\Arquivos PDF, PPT, DOC\Ciências de Dados - Anhanguera Ampli\Inteligência Artificial\Machine Learning I\MachineLearningI\Unidade_III\Aula_3_Clusterizacao.py&quot;, line 32, in &lt;module&gt;&#10;    dataset = exemplo.read_csv  #nesse momento devemos fazer a leitura do nosso dataset&#10;              ^^^^^^^^^^^^^^^^&#10;AttributeError: 'str' object has no attribute 'read_csv'" />
              <option name="response" value="" />
              <option name="responseDescription" value="Desculpe pelo erro. Parece que houve um equívoco na linha em que você está tentando ler o arquivo CSV. A função `read_csv` pertence à biblioteca pandas e não ao objeto de string `exemplo`. &#10;&#10;Para corrigir o erro, você precisa usar a função `pd.read_csv` para ler o arquivo CSV. Aqui está a linha corrigida:&#10;&#10;```python&#10;dataset = pd.read_csv(exemplo)  # nesse momento devemos fazer a leitura do nosso dataset&#10;```&#10;&#10;Certifique-se de que a variável `exemplo` contenha o caminho correto para o arquivo CSV que você deseja ler.&#10;&#10;Se você tiver mais dúvidas ou precisar de mais ajuda, por favor, me avise." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708662131497" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_3_Clusterizacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="f59294">
          <value>
            <ChatHistoryModel>
              <option name="id" value="f59294" />
              <option name="initiateTms" value="1708483770006" />
              <option name="request" value="crie um resumo sobre métodos de transformações lineares" />
              <option name="response" value="" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_2_Transformacoes_lineares.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
        <entry key="f6fe78">
          <value>
            <ChatHistoryModel>
              <option name="contextFilesPaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
              <option name="id" value="f6fe78" />
              <option name="initiateTms" value="1708740442490" />
              <option name="request" value="qual a fórmula da acurácia:" />
              <option name="response" value="" />
              <option name="responseDescription" value="A fórmula da acurácia é bastante simples. Ela é calculada dividindo o número de previsões corretas pelo número total de previsões. A fórmula da acurácia é:&#10;&#10;Acurácia = (Verdadeiros Positivos + Verdadeiros Negativos) / (Verdadeiros Positivos + Falsos Positivos + Verdadeiros Negativos + Falsos Negativos)&#10;&#10;Onde:&#10;- Verdadeiros Positivos são os exemplos positivos corretamente classificados.&#10;- Verdadeiros Negativos são os exemplos negativos corretamente classificados.&#10;- Falsos Positivos são os exemplos negativos erroneamente classificados como positivos.&#10;- Falsos Negativos são os exemplos positivos erroneamente classificados como negativos.&#10;&#10;A acurácia é uma métrica importante para avaliar a qualidade geral de um modelo de classificação, pois indica a proporção de previsões corretas em relação ao total de previsões. No entanto, é importante considerar outras métricas, como precisão e recall, dependendo do contexto do problema." />
              <option name="responseFileName" value="" />
              <option name="responseFilePath" value="" />
              <option name="responseTms" value="1708740446050" />
              <option name="usedLocalFilePaths">
                <list>
                  <option value="$PROJECT_DIR$/Unidade_III/Aula_4_Algoritmos_de_Classificacao.py" />
                </list>
              </option>
            </ChatHistoryModel>
          </value>
        </entry>
      </map>
    </option>
  </component>
  <component name="com.intellij.coverage.CoverageDataManagerImpl">
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_4_Algoritmos_de_Classificacao.coverage" NAME="Aula_4_Algoritmos_de_Classificacao Coverage Results" MODIFIED="1708742594510" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_III" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_3_Decisao_em_ML.coverage" NAME="Aula_3_Decisao_em_ML Coverage Results" MODIFIED="1708059654001" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_II" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_3_Densidades_probabilisticas.coverage" NAME="Aula_3_Densidades_probabilisticas Coverage Results" MODIFIED="1707439309723" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_I" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_4_Modelos_de_selecao.coverage" NAME="Aula_4_Modelos_de_selecao Coverage Results" MODIFIED="1708143108419" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_II" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_3_Distribuicoes_Probabilisticas.coverage" NAME="Aula_3_Distribuicoes_Probabilisticas Coverage Results" MODIFIED="1708405922462" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_III" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_4_Redes_neurais.coverage" NAME="Aula_4_Redes_neurais Coverage Results" MODIFIED="1707534668741" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_I" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_2_Transformacoes_lineares.coverage" NAME="Aula_2_Transformacoes_lineares Coverage Results" MODIFIED="1708665517928" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_III" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_1_Introducao_ao_aprendizado_de_maquina.coverage" NAME="Aula_1_Introducao_ao_aprendizado_de_maquina Coverage Results" MODIFIED="1707285976015" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_I" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_2_Modelos_de_aprendizagem_de_maquina.coverage" NAME="Aula_2_Modelos_de_aprendizagem_de_maquina Coverage Results" MODIFIED="1707286105873" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_I" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_2_Probabilidade_Bayesiana.coverage" NAME="Aula_2_Probabilidade_Bayesiana Coverage Results" MODIFIED="1707885166314" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_II" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_3_Clusterizacao.coverage" NAME="Aula_3_Clusterizacao Coverage Results" MODIFIED="1708665328773" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_III" />
    <SUITE FILE_PATH="coverage/MachineLearningI$Aula_1_Teoria_da_probabilidade.coverage" NAME="Aula_1_Teoria_da_probabilidade Coverage Results" MODIFIED="1707753573223" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/Unidade_II" />
  </component>
</project>